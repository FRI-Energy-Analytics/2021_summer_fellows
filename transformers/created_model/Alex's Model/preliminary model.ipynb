{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "coordinated-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, this needs to be ran twice\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Layer\n",
    "# import statement periodicly breaks, needs notebook to be restarted and sometimes for packages to be reinstalled\n",
    "#from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "spread-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "# todo: num fetures should be auto detected later based on array size, also these should be moved to a seperate file/ inputs\n",
    "num_fetures = 13\n",
    "num_epochs = 100\n",
    "epoch_steps = 500\n",
    "val_steps = 10\n",
    "test_train_split = 0.2\n",
    "random_seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "intimate-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking in variables to predict the median house price, sequence to single output analysis\n",
    "# todo: bring in well data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=test_train_split, seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "equal-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn data into a keras database\n",
    "train_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train, y_train, num_fetures,\n",
    ")\n",
    "val_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_test, y_test, num_fetures,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "found-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index feture doesn't work, likely due to the way the sequential model is implemented/ optimized\n",
    "# todo: fix getting the origional input for the dot product step\n",
    "class FeedForwardAttention(Layer):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardAttention, self).__init__()\n",
    "        self.index = 0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print(self.index)\n",
    "        self.index = self.index  + 1\n",
    "        print(inputs([ival]))\n",
    "        return tf.matmul(\n",
    "            inputs,\n",
    "            tf.cast(tf.reshape(x_train[self.index], [num_fetures, 1]), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "plain-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model archetecture\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation='softmax'),\n",
    "        # not sure how this step might effect the back propagation\n",
    "        FeedForwardAttention(),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=num_fetures, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=1, activation=\"relu\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "small-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    C:\\Users\\alexb\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-64-fa49257184cd>:14 call  *\n        print(inputs([ival]))\n\n    NameError: name 'ival' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-b93fe4c655ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 764\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    C:\\Users\\alexb\\anaconda3\\envs\\energyanalytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-64-fa49257184cd>:14 call  *\n        print(inputs([ival]))\n\n    NameError: name 'ival' is not defined\n"
     ]
    }
   ],
   "source": [
    "# run the model with a gradient decent optimizer and mean squared error\n",
    "# Model seems to instantly fall into the same local minima, I was previously able to get it to train lower but not\n",
    "# it doesn't seem to want to. I'll have to work further on this or just bring in the well data and hope for the best\n",
    "# note: it falls into same local minima without the new model, I might be doing this wrong\n",
    "model.compile(\n",
    "    optimizer=\"SGD\", loss=tf.keras.losses.MeanSquaredError(),\n",
    ")\n",
    "history = model.fit(\n",
    "    train_dataset.repeat(),\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=val_dataset.repeat(),\n",
    "    validation_steps=val_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
